CORE_CONF_fs_defaultFS=hdfs://hadoop:9000
CORE_CONF_hadoop_http_staticuser_user=root
CORE_CONF_hadoop_proxyuser_hue_hosts=*
CORE_CONF_hadoop_proxyuser_hue_groups=*
CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec
CORE_CONF_hadoop_proxyuser_root_groups=*
CORE_CONF_hadoop_proxyuser_root_hosts=*

# CORE_CONF_hadoop.tmp.dir=
# CORE_CONF_hadoop.security.authentication=simple
# CORE_CONF_hadoop.security.authorization=false
# CORE_CONF_hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
# CORE_CONF_hadoop.security.groups.cache.secs=300
# CORE_CONF_hadoop.security.key.provider.path=URL
# CORE_CONF_hadoop.security.key.provider.path.ftp=org.apache.hadoop.fs.ftp.FtpKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.http=org.apache.hadoop.fs.http.HttpKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.jceks=org.apache.hadoop.fs.jceks.JceksKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.localjceks=org.apache.hadoop.fs.local.LocalJceksKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.pkcs12=org.apache.hadoop.fs.pkcs12.PKCS12KeyProvider
# CORE_CONF_hadoop.security.key.provider.path.ssh=org.apache.hadoop.fs.ssh.SshKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.swarm=org.apache.hadoop.fs.swarm.SwarmKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.test=org.apache.hadoop.fs.TestKeyProvider

HDFS_CONF_dfs_webhdfs_enabled=true
HDFS_CONF_dfs_permissions_enabled=false
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false


YARN_CONF_yarn_log___aggregation___enable=true
YARN_CONF_yarn_log_server_url=http://hadoop:8188/applicationhistory/logs/
YARN_CONF_yarn_resourcemanager_recovery_enabled=true
YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4
YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true
YARN_CONF_yarn_resourcemanager_hostname=hadoop
YARN_CONF_yarn_resourcemanager_address=hadoop:8032
YARN_CONF_yarn_resourcemanager_scheduler_address=hadoop:8030
YARN_CONF_yarn_resourcemanager_resource__tracker_address=hadoop:8031
YARN_CONF_yarn_timeline___service_enabled=true
YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
YARN_CONF_yarn_timeline___service_hostname=hadoop
YARN_CONF_mapreduce_map_output_compress=true
YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec
YARN_CONF_yarn_nodemanager_resource_memory___mb=16384
YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle

MAPRED_CONF_mapreduce_framework_name=yarn
MAPRED_CONF_mapred_child_java_opts=-Xmx4096m
MAPRED_CONF_mapreduce_map_memory_mb=4096
MAPRED_CONF_mapreduce_reduce_memory_mb=8192
MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072m
MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144m
MAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/

# For Hive Configuration
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false

# HIVE Metastore
HIVE_SITE_CONF_hive_metastore_local=false
HIVE_SITE_CONF_hive_metastore_warehouse_dir=/user/hive/warehouse
HIVE_SITE_CONF_hive_metastore_port=9083
HIVE_SITE_CONF_hive_metastore_uris=thrift://hadoop:9083

# HIVE_SITE_CONF_metastore_catalog_default=hive
HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hadoop:5432/hivemetastore
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive
HIVE_SITE_CONF_datanucleus_autoCreateSchema=true
HIVE_SITE_CONF_datanucleus_fixedDatastore=true
HIVE_SITE_CONF_datanucleus_autoCreateTables=true
HIVE_SITE_CONF_hive_metastore_client_connect_retry_delay=5
HIVE_SITE_CONF_hive_metastore_client_socket_timeout=1800

# Hive server2
HIVE_SITE_CONF_hive_server2_enable_doAs=false
HIVE_SITE_CONF_hive_server2_thrift_http_port=10001
HIVE_SITE_CONF_hive_server2_thrift_port=10000
HIVE_SITE_CONF_hive_server2_transport_mode=binary
HIVE_SITE_CONF_hive_server2_webui_port=10002
HIVE_SITE_CONF_mapreduce_input_fileinputformat_input_dir_recursive=true
HIVE_SITE_CONF_hive_root_logger=DEBUG,console
HIVE_SITE_CONF_hive_server2_thrift_http_max_worker_threads=500
HIVE_SITE_CONF_hive_server2_thrift_http_min_worker_threads=5
# HIVE_SITE_CONF_hive_server2_transport_mode=http
# HIVE_SITE_CONF_hive_server2_thrift_http_path=cliservice
# HIVE_SITE_CONF_hive_server2_thrift_bind_host=hive-server2

# HIVE_SITE_CONF_hive_server2_authentication=NOSASL
# HIVE_SITE_CONF_hive_server2_thrift_bind_host=localhost
# HIVE_SITE_CONF_hive_metastore_event_db_notification_api_auth=false

# hive.server2.thrift.http.path=cliservice
# hive.server2.use.SSL=true
# hive.server2.keystore.path=Set this to your keystore path.
# hive.server2.keystore.password=Set this to your keystore password.

HIVE_SITE_CONF_hive_execution_engine=spark
HIVE_SITE_CONF_spark_master=yarn
HIVE_SITE_CONF_spark_eventLog_enabled=true
HIVE_SITE_CONF_spark_serializer=org.apache.spark.serializer.KryoSerializer
HIVE_SITE_CONF_spark_eventLog_dir=hdfs:///user/spark/spark2-history/
HIVE_SITE_CONF_spark_driver_memory=1g
HIVE_SITE_CONF_spark_executor_memory=2g
HIVE_SITE_CONF_spark_executor_instances=1
HIVE_SITE_CONF_spark_executor_cores=1
HIVE_SITE_CONF_spark_network_timeout=600s # test
# # HIVE_SITE_CONF_spark_yarn=hdfs://localhost:8020/spark-jars/*

# For Spark Configuration
SPARK_CONFING_spark_master=yarn
SPARK_CONFING_spark_driver_memory=2g
SPARK_CONFING_spark_executor_memory=2g
SPARK_CONFING_spark_executor_instances=2
SPARK_CONFING_spark_executor_cores=2
SPARK_CONFING_spark_serializer=org.apache.spark.serializer.KryoSerializer

SPARK_CONFING_spark_eventLog_dir=hdfs:///user/spark/spark2-history/
SPARK_CONFING_spark_eventLog_enabled=true
SPARK_CONFING_spark_executor_extraJavaOptions=-XX:+UseNUMA
SPARK_CONFING_spark_executor_extraJavaOptions=-XX:+UseNUMA
# SPARK_CONFING_spark_executor_extraLibraryPath=/usr/yava/current/hadoop-client/lib/native:/usr/yava/current/hadoop-client/lib/native/Linux-amd64-64
SPARK_CONFING_spark_history_fs_cleaner_enabled=true
SPARK_CONFING_spark_history_fs_cleaner_interval=7d
SPARK_CONFING_spark_history_fs_cleaner_maxAge=90d
# SPARK_CONFING_spark_history_fs_logDirectory=hdfs:///user/spark/spark2-history/
SPARK_CONFING_spark_history_kerberos_keytab=none 
SPARK_CONFING_spark_history_kerberos_principal=none
SPARK_CONFING_spark_history_provider=org.apache.spark.deploy.history.FsHistoryProvider
SPARK_CONFING_spark_history_ui_port=18081
SPARK_CONFING_spark_io_compression_lz4_blockSize=128kb
SPARK_CONFING_spark_shuffle_file_buffer=1m
SPARK_CONFING_spark_shuffle_io_backLog=8192
SPARK_CONFING_spark_shuffle_io_serverThreads=128
SPARK_CONFING_spark_shuffle_unsafe_file_output_buffer=5m

# Spark connect Hive Metastore
SPARK_CONFING_spark_sql_warehouse_dir=hdfs:///user/hive/warehouse
SPARK_CONFING_spark_hadoop_hive_metastore_uris=thrift://hadoop:9083

SPARK_CONFING_spark_sql_autoBroadcastJoinThreshold=-1
SPARK_CONFING_spark_sql_broadcastTimeout=300
SPARK_CONFING_spark_sql_catalogImplementation=hive
# SPARK_CONFING_spark_sql_hive_convertMetastoreOrc=true

# SPARK_CONFING_spark_sql_hive_metastore_jars=/usr/yava/current/spark2-client/standalone-metastore/*:/usr/yava/current/tez-client/*:/usr/yava/current/spark2-client/jars/*

SPARK_CONFING_spark_sql_hive_metastore_version=2.3.9

SPARK_CONFING_spark_sql_orc_filterPushdown=true
SPARK_CONFING_spark_sql_orc_impl=native
SPARK_CONFING_spark_sql_statistics_fallBackToHdfs=true
SPARK_CONFING_spark_unsafe_sorter_spill_reader_buffer_size=1m
# SPARK_CONFING_spark_yarn_historyServer_address=0.0.0.0:18081
SPARK_CONFING_spark_yarn_queue=default
SPARK_CONFING_spark_network_timeout=600s